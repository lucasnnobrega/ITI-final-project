{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Template.ipynb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Template import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](WhatsApp Image 2020-03-28 at 09.43.26.jpeg \"Instruções para o projeto final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[34;42m1\u001b[0m/                         \u001b[01;32mStudy.ipynb\u001b[0m*\r\n",
      " \u001b[01;32m1.pgm\u001b[0m*                     \u001b[01;32mtemp0.txt\u001b[0m*\r\n",
      " \u001b[01;32mcompressor.py\u001b[0m*             \u001b[01;32mtemp1.txt\u001b[0m*\r\n",
      "\u001b[01;32m'concat bitstream.ipynb'\u001b[0m*   \u001b[01;32mtemp2.txt\u001b[0m*\r\n",
      " \u001b[01;32mconstantes.py\u001b[0m*             \u001b[01;32mtemp3.txt\u001b[0m*\r\n",
      " \u001b[01;32mdescompressor.py\u001b[0m*          \u001b[01;32mtemp4.txt\u001b[0m*\r\n",
      "\u001b[01;32m'Final Project.ipynb'\u001b[0m*      \u001b[01;32mTemplate.ipynb\u001b[0m*\r\n",
      " \u001b[01;32mmain2.py\u001b[0m*                  \u001b[01;32mtemp.txt\u001b[0m*\r\n",
      " \u001b[01;32mmay-7-update.ipynb\u001b[0m*        \u001b[01;32mUntitled1.ipynb\u001b[0m*\r\n",
      " \u001b[01;32mmonitor2.py\u001b[0m*               \u001b[01;32mUntitled2.ipynb\u001b[0m*\r\n",
      " \u001b[34;42morl_faces\u001b[0m/                 \u001b[01;32mUntitled.ipynb\u001b[0m*\r\n",
      " \u001b[01;32mProjeto2019.2.pdf\u001b[0m*         \u001b[01;32mUntitled.py\u001b[0m*\r\n",
      " \u001b[34;42m__pycache__\u001b[0m/              \u001b[01;32m'WhatsApp Image 2020-03-28 at 09.43.26.jpeg'\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"900\"\n",
       "            src=\"./Projeto2019.2.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc9a44e6198>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"./Projeto2019.2.pdf\", width=1000, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by:\n",
    "\n",
    "|Nome|Matricula|\n",
    "|-|-|\n",
    "|Lucas Nogueira Nobrega|2016017049|    \n",
    "|Luciano Junior||\n",
    "|Thales Soares||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "rand_number = random.randint(0,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Comprimir(fileName, k=9):\n",
    "    if not os.path.exists(fileName):\n",
    "        print(RED, \"Arquivo Não Existe\", RESET)\n",
    "        sys.exit()\n",
    "\n",
    "    data = open(fileName, 'rb').read()\n",
    "\n",
    "    # time.sleep(10)\n",
    "    resultComprm, size, txt = compress(data, k)\n",
    "\n",
    "    print(\"Compressão Finalizada \\nCriando Arquvios\")\n",
    "    createComprmFiles(resultComprm, size, fileName, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(uncompressed, k=9):\n",
    "\n",
    "    if k < 9:\n",
    "        print(\"K Inválido\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Tamanho inicial do dicionario\n",
    "    dict_size = 256\n",
    "    # Tamanho maximo do dicionario, com base no parametro K\n",
    "    dict_max_lenght = int(math.pow(2, k))\n",
    "    # Construindo o dicionario {\"simbolo\": index}\n",
    "    dictionary = {chr(i): i for i in range(dict_size)}\n",
    "\n",
    "    w = \"\"\n",
    "    result = []\n",
    "\n",
    "    for c in uncompressed:\n",
    "        # Adicione um novo caractere a w\n",
    "        new_string = w + chr(c)\n",
    "        # Se new_string ja esta no dicionario, entao aumente o tamanho de new_string\n",
    "        if new_string in dictionary:\n",
    "            # colocando o valor em w para aumentar a quantidade de simbolos\n",
    "            w = new_string\n",
    "        # Se nao tiver, precisa adicionar pois esse simbolo sera usado\n",
    "        else:\n",
    "            # Adicione no final do result o valor de w para formar o arquivo final\n",
    "            result.append(dictionary[w])\n",
    "\n",
    "            # Adicionar a new_string ao dicionario, com valor = dict_size\n",
    "            dictionary[new_string] = dict_size\n",
    "            # Incrementar o valor do dicionario para que o prox a ser inserido tenha valor diferente\n",
    "            dict_size += 1\n",
    "\n",
    "            # Converter o valor encontrado para char\n",
    "            w = chr(c)\n",
    "\n",
    "            # Resetando a Janela deslizante, que eh equivalente ao comprimento do dicionario(2**K)\n",
    "            if len(dictionary) == dict_max_lenght:\n",
    "                # Reseta o dicionario\n",
    "                dict_size = 256\n",
    "                # se w estiver com algo, entao adicione no dicionario\n",
    "                if w:\n",
    "                    result.append(dictionary[w])\n",
    "                w = \"\"\n",
    "                # Limpe o dicionario\n",
    "                dictionary.clear()\n",
    "                # Reconstruindo o dicionario com as entradas padroes\n",
    "                dictionary = {chr(i): i for i in range(dict_size)}\n",
    "\n",
    "    # Verificando se nao restou nada no w\n",
    "    if w:\n",
    "        result.append(dictionary[w])\n",
    "\n",
    "    return result, dict_max_lenght, uncompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_dict(uncompressed, k=9):\n",
    "    \"\"\"\n",
    "    Example function with PEP 484 type annotations.\n",
    "\n",
    "    Args:\n",
    "        uncompress: The first parameter.\n",
    "        k: The second parameter.\n",
    "\n",
    "    Returns:\n",
    "        return result, dict_max_lenght, uncompressed, dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    if k < 9:\n",
    "        print(\"K Inválido\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Tamanho inicial do dicionario\n",
    "    dict_size = 256\n",
    "    # Tamanho maximo do dicionario, com base no parametro K\n",
    "    dict_max_lenght = int(math.pow(2, k))\n",
    "    # Construindo o dicionario {\"simbolo\": index}\n",
    "    dictionary = {chr(i): i for i in range(dict_size)}\n",
    "\n",
    "    w = \"\"\n",
    "    result = []\n",
    "\n",
    "    for c in uncompressed:\n",
    "        # Adicione um novo caractere a w\n",
    "        new_string = w + chr(c)\n",
    "        # Se new_string ja esta no dicionario, entao aumente o tamanho de new_string\n",
    "        if new_string in dictionary:\n",
    "            # colocando o valor em w para aumentar a quantidade de simbolos\n",
    "            w = new_string\n",
    "        # Se nao tiver, precisa adicionar pois esse simbolo sera usado\n",
    "        else:\n",
    "            # Adicione no final do result o valor de w para formar o arquivo final\n",
    "            result.append(dictionary[w])\n",
    "\n",
    "            # Adicionar a new_string ao dicionario, com valor = dict_size\n",
    "            dictionary[new_string] = dict_size\n",
    "            # Incrementar o valor do dicionario para que o prox a ser inserido tenha valor diferente\n",
    "            dict_size += 1\n",
    "\n",
    "            # Converter o valor encontrado para char\n",
    "            w = chr(c)\n",
    "\n",
    "            # Resetando a Janela deslizante, que eh equivalente ao comprimento do dicionario(2**K)\n",
    "            if len(dictionary) == dict_max_lenght:\n",
    "                # Reseta o dicionario\n",
    "                dict_size = 256\n",
    "                # se w estiver com algo, entao adicione no dicionario\n",
    "                if w:\n",
    "                    result.append(dictionary[w])\n",
    "                w = \"\"\n",
    "                # Limpe o dicionario\n",
    "                dictionary.clear()\n",
    "                # Reconstruindo o dicionario com as entradas padroes\n",
    "                dictionary = {chr(i): i for i in range(dict_size)}\n",
    "\n",
    "    # Verificando se nao restou nada no w\n",
    "    if w:\n",
    "        result.append(dictionary[w])\n",
    "\n",
    "    return result, dict_max_lenght, uncompressed, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_quantity = 40\n",
    "sbj_photos = 10\n",
    "\n",
    "people_raw = list() # ALL 10 PHOTOS FROM EACH PERSON\n",
    "people_subjects = list() # FIRST PHOTO FROM EACH PERSON\n",
    "people_dataset_raw = list() # 9 PHOTOS FOR EACH PERSON DATASET\n",
    "\n",
    "for j in range(1, subjects_quantity+1):\n",
    "    # For para cada imagem\n",
    "    for i in range(1, sbj_photos+1):\n",
    "        people_raw.append(np.array(open(f'./orl_faces/orl_faces/s{j}/{i}.pgm', 'rb').read()))\n",
    "        # For randomic result, put here the randomic generator\n",
    "        if i == rand_number:\n",
    "            people_subjects.append(np.array(open(f'./orl_faces/orl_faces/s{j}/{i}.pgm', 'rb').read()))\n",
    "        else:\n",
    "            people_dataset_raw.append(np.array(open(f'./orl_faces/orl_faces/s{j}/{i}.pgm', 'rb').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_dataset_raw_np = np.array(people_dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_dataset_raw_np = np.reshape(people_dataset_raw, (40,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_dataset_raw_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_dataset_raw_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = list()\n",
    "for person_id in range(40):\n",
    "    aux_bigfig = people_dataset_raw_np[person_id][0]\n",
    "    for picture_id in range(1,9):\n",
    "        aux_bigfig = aux_bigfig + people_dataset_raw_np[person_id][picture_id]\n",
    "    new_dataset.append(aux_bigfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = np.array(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea for the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira foto o dicionário é a tabela ascii, quando tu comprimir a primeira foto os dados dela entra no dicionário tbm, aí fica ascii + info foto 1 e assim vai até o dicionário ficar com 2**k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionaries_universe = list()\n",
    "for person in range(new_dataset.shape[0]):\n",
    "    result, dict_max_lenght, uncompressed, dictionary = compress_dict(new_dataset[person])\n",
    "    dictionaries_universe.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, list, dict)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionaries_universe), type(dictionaries_universe), type(dictionaries_universe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_subjects_np = np.array(people_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries_instances = list()\n",
    "for person in range(people_subjects_np.shape[0]):\n",
    "    result, dict_max_lenght, uncompressed, dictionary = compress_dict(new_dataset[person])\n",
    "    dictionaries_instances.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionaries_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerado o dicionario, agora converter para Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries_universe_np = list()  \n",
    "for dicionario in dictionaries_universe:\n",
    "    dictionaries_universe_np.append(np.array(list(dicionario.items())))\n",
    "dictionaries_universe_np = np.array(dictionaries_universe_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40,), numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaries_universe_np.shape, type(dictionaries_universe_np), type(dictionaries_universe_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries_instances_np = list()  \n",
    "for dicionario in dictionaries_instances:\n",
    "    dictionaries_instances_np.append(np.array(list(dicionario.items())))\n",
    "dictionaries_instances_np = np.array(dictionaries_instances_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40,), numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionaries_instances_np.shape, type(dictionaries_instances_np), type(dictionaries_instances_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labels to KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    }
   ],
   "source": [
    "labels = [i for i in range(40)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring machine learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructor of KNeighborsClassifier \n",
    "neigh = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-56df37793e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit receive parameters to learn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionaries_universe_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \"\"\"\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#fit receive parameters to learn\n",
    "neigh.fit(dictionaries_universe_np, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "\n",
    "for image in crop_unique:\n",
    "    y_predict.append(neigh.predict([image.real]))\n",
    "    print(neigh.predict([image.real]), end= \" \")\n",
    "#casting to transform the array in np_array\n",
    "y_predict = np.array(y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of correct labels\n",
    "y_true = [i for i in range(0,40)]\n",
    "y_pred = y_predict\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_matrix)\n",
    "plt.figure(figsize = (10*2,7*2))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINISHED SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STARTING THE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of the project consists in:\n",
    "\n",
    "1. Create the list of redimensioned image\n",
    "1. Analyze the Mean Square Error (MSE)\n",
    "1. Classify samples from MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the list of redimensioned image:\n",
    "    we need to create a function that returns only the relevant part of the image. That integer input will be the dimensions of the usable image data. The dimensions used in this projest are: 2x2 until 30x30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut image according to the last dimension\n",
    "def crop_img(n, image):\n",
    "    #current dimensions of imagens in the database\n",
    "    image_width = 92\n",
    "    image_height = 112\n",
    "    \n",
    "    # center of the image\n",
    "    x = image_height//2\n",
    "    y = image_width//2\n",
    "    \n",
    "    # RADIUS OF THE AREA\n",
    "    r = n//2\n",
    "    \n",
    "    odd = 0\n",
    "    #testing if image is odd\n",
    "    if n % 2 != 0:\n",
    "        odd = -1\n",
    "    \n",
    "    return image[x-r+odd:x+r,y-r+odd:y+r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = np.array(people_fft_s)\n",
    "people.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = crop_img(30, people_raw[0])\n",
    "cropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show redimensioned image\n",
    "plt.imshow(cropped, \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyze the Mean Square Error (MSE):\n",
    "    we need to create a function that calculate the distante between the samples and the image that we want classify, for that we testing two algorits:\n",
    "\n",
    "1. First case with SkLearn\n",
    "\n",
    "\n",
    "2. Second case with other implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropped all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dimension range\n",
    "dimension = 30\n",
    "#to original image, labeled\n",
    "crop_full = []\n",
    "# to each user, labeless\n",
    "crop_unique = []\n",
    "# to add crop image in crop_full, unidimensional array\n",
    "for image in people_fft_s:\n",
    "    crop_full.append(np.array(crop_img(dimension, image)).flatten())\n",
    "    \n",
    "# to add crop image in crop_full, unidimensional array  \n",
    "for image in people_unique_fft_s:\n",
    "    crop_unique.append(np.array(crop_img(dimension, image)).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First case with SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(crop_full)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labels to KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(40) for j in range(9)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring machine learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructor of KNeighborsClassifier \n",
    "neigh = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit receive parameters to learn\n",
    "neigh.fit(X.real, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "\n",
    "for image in crop_unique:\n",
    "    y_predict.append(neigh.predict([image.real]))\n",
    "    print(neigh.predict([image.real]), end= \" \")\n",
    "#casting to transform the array in np_array\n",
    "y_predict = np.array(y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of correct labels\n",
    "y_true = [i for i in range(0,40)]\n",
    "y_pred = y_predict\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_matrix)\n",
    "plt.figure(figsize = (10*2,7*2))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Second case, KNN with mean square error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(subjects, dataset, mode):\n",
    "    \n",
    "    nearest_indexes = []\n",
    "    nearest_labels = []\n",
    "    \n",
    "    for i, labeless_image in enumerate(subjects):\n",
    "        \n",
    "        nearest = math.inf\n",
    "        nearest_index = 0\n",
    "        \n",
    "        for j, labeled_image in enumerate(dataset):\n",
    "            \n",
    "            if mode == 'r':\n",
    "                mse = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "            if mode == 'i':\n",
    "                mse = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "            if mode == 'ri':\n",
    "                mse_real = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "                mse_imag = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "                mse = mse_real + mse_imag\n",
    "            if mse < nearest:\n",
    "                nearest = mse\n",
    "                nearest_index = j\n",
    "        nearest_indexes.append(nearest_index)\n",
    "        nearest_labels.append(labels[nearest_index])\n",
    "        \n",
    "    return nearest_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real = []\n",
    "\n",
    "for dimension in dimensions:\n",
    "    print(\"Dimension: \", dimension)\n",
    "    subject = [crop_img(dimension, i) for i in people_unique_fft_s]\n",
    "    dataset = [crop_img(dimension, i) for i in people_fft_s]\n",
    "    labels_predict_real.append(knn(subject, dataset, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels_predict_real).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "graph_real = []\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real):\n",
    "    print(\"For dimension {:2}, and using only real the result is: {} {}\" .format((i+2), accuracy_score(y_true, y_pred), accuracy_score(y_true, y_pred, normalize=False)))\n",
    "    graph_real.append([accuracy_score(y_true, y_pred), i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of real iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_real = np.array(graph_real).transpose()\n",
    "\n",
    "plt.bar(graph_real[1], graph_real[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGINARY ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_imag = []\n",
    "\n",
    "for dimension in dimensions:\n",
    "    print(\"Dimension: \", dimension)\n",
    "    subject = [crop_img(dimension, i) for i in people_unique_fft_s]\n",
    "    dataset = [crop_img(dimension, i) for i in people_fft_s]\n",
    "    labels_predict_imag.append(knn(subject, dataset, 'i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels_predict_imag).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "graph_imag = []\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_imag):\n",
    "    print(\"For dimension {:2}, and using only imaginary the result is: {} {}\" .format((i+2), accuracy_score(y_true, y_pred), accuracy_score(y_true, y_pred, normalize=False)))\n",
    "    graph_imag.append([accuracy_score(y_true, y_pred), i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_imag = np.array(graph_imag).transpose()\n",
    "\n",
    "plt.bar(graph_imag[1], graph_imag[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL + IMAGINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real_imag = []\n",
    "\n",
    "for dimension in dimensions:\n",
    "    print(\"Dimension: \", dimension)\n",
    "    subject = [crop_img(dimension, i) for i in people_unique_fft_s]\n",
    "    dataset = [crop_img(dimension, i) for i in people_fft_s]\n",
    "    labels_predict_real_imag.append(knn(subject, dataset, 'ri'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels_predict_real_imag).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "graph_real_imag = []\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real_imag):\n",
    "    print(\"For dimension {:2}, and using real and imaginary values, the result is: {} {}\" .format((i+2), accuracy_score(y_true, y_pred), accuracy_score(y_true, y_pred, normalize=False)))\n",
    "    graph_real_imag.append([accuracy_score(y_true, y_pred), i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_real_imag = np.array(graph_real_imag).transpose()\n",
    "\n",
    "plt.bar(graph_real_imag[1], graph_real_imag[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL AND IMAGINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_for_last_exemple(subjects, dataset):\n",
    "    \n",
    "    nearest_indexes = []\n",
    "    nearest_labels = []\n",
    "    \n",
    "    for i, labeless_image in enumerate(subjects):\n",
    "        \n",
    "        nearest = math.inf\n",
    "        nearest_index = 0\n",
    "        \n",
    "        for j, labeled_image in enumerate(dataset):\n",
    "            mse_real_imag = mean_squared_error(labeled_image.real, labeless_image.imag)\n",
    "            mse_imag_real = mean_squared_error(labeled_image.imag, labeless_image.real)\n",
    "            mse_real = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "            mse_imag = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "\n",
    "            distance_list = [mse_real_imag, mse_imag_real, mse_real, mse_imag]\n",
    "            mse = sorted(distance_list)[0]\n",
    "            if mse < nearest:\n",
    "                nearest = mse\n",
    "                nearest_index = j\n",
    "        nearest_indexes.append(nearest_index)\n",
    "        nearest_labels.append(labels[nearest_index])\n",
    "        \n",
    "    return nearest_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real_and_imag = []\n",
    "\n",
    "for dimension in dimensions:\n",
    "    print(\"Dimension: \", dimension)\n",
    "    subject = [crop_img(dimension, i) for i in people_unique_fft_s]\n",
    "    dataset = [crop_img(dimension, i) for i in people_fft_s]\n",
    "    labels_predict_real_and_imag.append(knn_for_last_exemple(subject, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels_predict_real_and_imag).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "graph_real_and_imag = []\n",
    "\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real_and_imag):\n",
    "    print(\"For dimension {:2}, and using real and imaginary values, the result is: {} {}\" .format((i+2), accuracy_score(y_true, y_pred), accuracy_score(y_true, y_pred, normalize=False)))\n",
    "    graph_real_and_imag.append([accuracy_score(y_true, y_pred), i+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram for the real and imaginary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_real_and_imag = np.array(graph_real_and_imag).transpose()\n",
    "\n",
    "plt.bar(graph_real_and_imag[1], graph_real_and_imag[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the knn \n",
    "Altering the dataset that picture 1 of person 1 now is picture 1 of person 2 and picture 1 for person 2 is picture 1 of person 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLECTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_quantity = 40\n",
    "sbj_photos = 10\n",
    "\n",
    "people_raw = list() # ALL 10 PHOTOS FROM EACH PERSON\n",
    "people_subjects = list() # FIRST PHOTO FROM EACH PERSON\n",
    "people_dataset_raw = list() # 9 PHOTOS FOR EACH PERSON DATASET\n",
    "\n",
    "for j in range(1, subjects_quantity+1):\n",
    "    # For para cada imagem\n",
    "    for i in range(1, sbj_photos+1):\n",
    "        people_raw.append(np.array(cv2.imread(f'./orl_faces_first_image_changed_12_21/orl_faces/s{j}/{i}.pgm',0)))\n",
    "        if i == 1:\n",
    "            people_subjects.append(np.array(cv2.imread(f'./orl_faces_first_image_changed_12_21/orl_faces/s{j}/{i}.pgm',0)))\n",
    "        if i != 1:\n",
    "            people_dataset_raw.append(np.array(cv2.imread(f'./orl_faces_first_image_changed_12_21/orl_faces/s{j}/{i}.pgm',0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset size: {len(people_dataset_raw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW DATA SHOW UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 3, 10\n",
    "\n",
    "for j in range(0,nrows*ncols,10):\n",
    "    for i in range(1,11):\n",
    "        plt.subplot(nrows, ncols, i + j)\n",
    "        plt.imshow(people_raw[i-1 + j], cmap = 'gray')\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BELOW, ALL THE ARRAYS ARE DATASET ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an array with fourier transform from raw data set array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_fft = [np.fft.fft2(person) for person in people_dataset_raw]\n",
    "\n",
    "people_unique_fft = [np.fft.fft2(person) for person in people_subjects]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'people_fft' is now an array containing a fourier transformed version of each photo from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude an ideal analysis, the original fourier transformed image is not the easiest data to work with, so, the purpose of the next command is to create a  version of each imagem with it's relative relevant data shifted to the center of the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_fft_s = [np.fft.fftshift(person) for person in people_fft]\n",
    "\n",
    "people_unique_fft_s = [np.fft.fftshift(person) for person in people_unique_fft]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, showing one example from the raw data, the fourier transformed, and the shifted one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(131)\n",
    "plt.imshow(people_raw[0], cmap = 'gray')\n",
    "plt.title('Input'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.abs(people_fft[0]), cmap = 'gray')\n",
    "plt.title('Fourier transform'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.abs(people_fft_s[0]), cmap = 'gray')\n",
    "plt.title('Shifted F transform'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINISHED SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STARTING THE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of the project consists in:\n",
    "\n",
    "1. Create the list of redimensioned image\n",
    "1. Analyze the Mean Square Error (MSE)\n",
    "1. Classify samples from MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the list of redimensioned image:\n",
    "    we need to create a function that returns only the relevant part of the image. That integer input will be the dimensions of the usable image data. The dimensions used in this projest are: 2x2 until 30x30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut image according to the last dimension\n",
    "def crop_img(n, image):\n",
    "    #current dimensions of imagens in the database\n",
    "    image_width = 92\n",
    "    image_height = 112\n",
    "    \n",
    "    # center of the image\n",
    "    x = image_height//2\n",
    "    y = image_width//2\n",
    "    \n",
    "    # RADIUS OF THE AREA\n",
    "    r = n//2\n",
    "    \n",
    "    odd = 0\n",
    "    #testing if image is odd\n",
    "    if n % 2 != 0:\n",
    "        odd = -1\n",
    "    \n",
    "    return image[x-r+odd:x+r,y-r+odd:y+r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = np.array(people_fft_s)\n",
    "people.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = crop_img(30, people_raw[0])\n",
    "cropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show redimensioned image\n",
    "plt.imshow(cropped, \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyze the Mean Square Error (MSE):\n",
    "    we need to create a function that calculate the distante between the samples and the image that we want classify, for that we testing two algorits:\n",
    "\n",
    "1. First case with SkLearn\n",
    "\n",
    "\n",
    "2. Second case with other implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropped all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dimension range\n",
    "dimension = 30\n",
    "#to original image, labeled\n",
    "crop_full = []\n",
    "# to each user, labeless\n",
    "crop_unique = []\n",
    "# to add crop image in crop_full, unidimensional array\n",
    "for image in people_fft_s:\n",
    "    crop_full.append(np.array(crop_img(dimension, image)).flatten())\n",
    "    \n",
    "# to add crop image in crop_full, unidimensional array  \n",
    "for image in people_unique_fft_s:\n",
    "    crop_unique.append(np.array(crop_img(dimension, image)).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First case with SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(crop_full)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labels to KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(40) for j in range(9)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring machine learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructor of KNeighborsClassifier \n",
    "neigh = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit receive parameters to learn\n",
    "neigh.fit(X.real, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "\n",
    "for image in crop_unique:\n",
    "    y_predict.append(neigh.predict([image.real]))\n",
    "    print(neigh.predict([image.real]), end= \" \")\n",
    "#casting to transform the array in np_array\n",
    "y_predict = np.array(y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of correct labels\n",
    "y_true = [i for i in range(0,40)]\n",
    "y_pred = y_predict\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_matrix)\n",
    "plt.figure(figsize = (10*2,7*2))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Second case, KNN with mean square error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(subjects, dataset, mode):\n",
    "    \n",
    "    nearest_indexes = []\n",
    "    nearest_labels = []\n",
    "    \n",
    "    for i, labeless_image in enumerate(subjects):\n",
    "        \n",
    "        nearest = math.inf\n",
    "        nearest_index = 0\n",
    "        \n",
    "        for j, labeled_image in enumerate(dataset):\n",
    "            \n",
    "            if mode == 'r':\n",
    "                mse = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "            if mode == 'i':\n",
    "                mse = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "            if mode == 'ri':\n",
    "                mse_real = mean_squared_error(labeled_image.real, labeless_image.real)\n",
    "                mse_imag = mean_squared_error(labeled_image.imag, labeless_image.imag)\n",
    "                mse = mse_real + mse_imag\n",
    "            if mse < nearest:\n",
    "                nearest = mse\n",
    "                nearest_index = j\n",
    "        nearest_indexes.append(nearest_index)\n",
    "        nearest_labels.append(labels[nearest_index])\n",
    "        \n",
    "    return nearest_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [i for i in range(2,31)]\n",
    "\n",
    "labels_predict_real = []\n",
    "\n",
    "for dimension in dimensions:\n",
    "    print(\"Dimension: \", dimension)\n",
    "    subject = [crop_img(dimension, i) for i in people_unique_fft_s]\n",
    "    dataset = [crop_img(dimension, i) for i in people_fft_s]\n",
    "    labels_predict_real.append(knn(subject, dataset, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels_predict_real).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [i for i in range(0,40)]\n",
    "\n",
    "graph_real = []\n",
    "\n",
    "for i, y_pred in enumerate(labels_predict_real):\n",
    "    print(\"For dimension {:2}, and using only real the result is: {} {}\" .format((i+2), accuracy_score(y_true, y_pred), accuracy_score(y_true, y_pred, normalize=False)))\n",
    "    graph_real.append([accuracy_score(y_true, y_pred), i+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result isn't 1.00 or 40 because the two photos are wrongs, proof that the programm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of real iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_real = np.array(graph_real).transpose()\n",
    "\n",
    "plt.bar(graph_real[1], graph_real[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
